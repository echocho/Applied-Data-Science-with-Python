{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1: Working with Text in Python\n",
    "\n",
    "## Introduction to Text Mining\n",
    "### What can be done with text?\n",
    "1. parse text.\n",
    "2. find/idenify/extract relevant information from text.\n",
    "3. classify text documents.\n",
    "4. search for relevant text documents.\n",
    "5. sentiment ansysis.\n",
    "6. topic modeling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Text in Python\n",
    "\n",
    "### Primitive Constructs in Text\n",
    "1. sentencs/ input strings.\n",
    "2. words ro tokens.\n",
    "3. characters.\n",
    "4. documents, larger files\n",
    "\n",
    "### Some word comparison fucntions\n",
    "1. s.startwith(t).\n",
    "2. s.endswith(t).\n",
    "3. t in s.\n",
    "4. s.isupper(); s.islower(); s.istitle().\n",
    "5. s.isalpha(); s.isdigit(); s.isalnum().\n",
    "\n",
    "### String operations (which I didn't use that often)\n",
    "1. s.splitliens()\n",
    "2. s.titlecase()\n",
    "3. s.find(t); s.rfind(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Expressions\n",
    "\n",
    "e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To extract hashtags from tweet\n",
    "import re\n",
    "tweet = \"@nltk Text analysis is awesome! #regex #pandas #python\"\n",
    "res = [re.findall('#[a-zA-Z0-9]+', tweet)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-characters: Character matches\n",
    "1. . \n",
    "2. ^\n",
    "3. $\n",
    "4. []\n",
    "5. [a-z]\n",
    "6. [^abc]: matches a character that is not a, b or c\n",
    "7. a|b: matches either a or b, where a and b are strings\n",
    "8. (): scoping for operators\n",
    "\n",
    "### Meta-characters: Character symbols\n",
    "1. \\b: matches word boundary\n",
    "2. \\d: any digit, ==[0-9]\n",
    "3. \\D:  ==[^0-9]\n",
    "4. \\s: any whitespace, ==[ \\t\\n\\r\\f\\v]\n",
    "5. \\S: any non-whitespace, ==[^ \\t\\n\\r\\f\\v]\n",
    "6. \\w: alphanumeric character, ==[a-zA-Z0-9]\n",
    "7. \\W: ==[^a-zA-Z0-9]\n",
    "\n",
    "### Meta-characters: Repetitions\n",
    "1. * : matches zero or more occurrences\n",
    "2. + : matches one or more occurrences\n",
    "3. ? : mathces zero or one occurrences\n",
    "4. {n} : exactly n repetitions, n >= 0\n",
    "5. {n,}: at least n repetitions\n",
    "6. {,n}: at most n repetitions\n",
    "7. {m,n}: at least m and at most n repetitions\n",
    "\n",
    "### Regular Expression for Dates\n",
    "```python\n",
    "dateStr = '23-10-2002\\n23/10/2002\\n23/10/02\\n10/23/2002\\n23 Oct 2002\\n23 October 2002\\nOct 23, 2002\\nOctober 23, 2002\\n'\n",
    "att1 = re.findall(r'\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}', dateStr)\n",
    "att2 = re.findall(r'\\d{1,2} (?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|SEp|Oct|Nov|Dec)[a-z]* \\d{2,4}', dateStr)\n",
    "att3 = re.findall(r'(?:\\d{1,2} )?(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|SEp|Oct|Nov|Dec)[a-z]* (?:\\d{1,2}, )?\\d{4}', dateStr)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-10-2002\n",
      "23/10/2002\n",
      "23/10/02\n",
      "10/23/2002\n",
      "23 Oct 2002\n",
      "23 October 2002\n",
      "Oct 23, 2002\n",
      "October 23, 2002\n",
      "\n",
      "['23 Oct 2002', '23 October 2002']\n",
      "['23-10-2002', '23/10/2002', '23/10/02', '10/23/2002']\n",
      "['23 Oct 2002', '23 October 2002', 'Oct 23, 2002', 'October 23, 2002']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "dateStr = '23-10-2002\\n23/10/2002\\n23/10/02\\n10/23/2002\\n23 Oct 2002\\n23 October 2002\\nOct 23, 2002\\nOctober 23, 2002\\n'\n",
    "print(dateStr)\n",
    "att1 = re.findall(r'\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}', dateStr)\n",
    "att2 = re.findall(r'\\d{1,2} (?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|SEp|Oct|Nov|Dec)[a-z]* \\d{2,4}', dateStr)\n",
    "att3 = re.findall(r'(?:\\d{1,2} )?(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|SEp|Oct|Nov|Dec)[a-z]* (?:\\d{1,2}, )?\\d{4}', dateStr)\n",
    "print(att2)\n",
    "print(att1)\n",
    "print(att3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Internationalization and Issues with Non-ASCII Characters\n",
    "### English and ASCII\n",
    "ASCII: American Standard Code for Information Interchange\n",
    "\n",
    "### Other Character Encodings\n",
    "1. IBM EBCDIC\n",
    "2. Latin-I\n",
    "3. JIS\n",
    "4. CCCII\n",
    "5. EUC\n",
    "6. Numerous other national standards\n",
    "\n",
    "Later, we have Unicode and utf-8.\n",
    "\n",
    "### Unicode\n",
    "1. Industry standard for encoding and representing text.\n",
    "2. Over 128,000 characters from 130+ scripts and symbol sets.\n",
    "4. Can be implement by different character endings.\n",
    "    - UTF-8: one byte for up to four bytes\n",
    "    - UTF-16: one or two 16-bit code units\n",
    "    - UTF-32: one 32-bit code unit\n",
    "    \n",
    "### UTF-8\n",
    "1. Unicode Tranformational Format - 8-bits.\n",
    "2. Variable length encoding: one to four bytes.\n",
    "3. Backward compatible with ASCII\n",
    "    - one byte codes same as ASCII\n",
    "4. Dominant character encoding for the Web\n",
    "5. In python:\n",
    "    - default in python3 \n",
    "    - in python2:\n",
    "        #-\\*- coding:utf-8 -*-\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Readings\n",
    "### Regular Expressions\n",
    "[Regular expressions documentation in Python 3](https://docs.python.org/3/library/re.html)\n",
    "\n",
    "### Tips and tricks of the trade for cleaning text in Python\n",
    "https://stanford.edu/~rjweiss/public_html/IRiSS2013/text2/notebooks/cleaningtext.html\n",
    "https://www.analyticsvidhya.com/blog/2014/11/text-data-cleaning-steps-python/\n",
    "http://ieva.rocks/2016/08/07/cleaning-text-for-nlp/\n",
    "https://chrisalbon.com/python/cleaning_text.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
